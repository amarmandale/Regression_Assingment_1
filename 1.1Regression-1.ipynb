{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbfb2b6-c349-423e-b3a4-8f6a3dc7fc92",
   "metadata": {},
   "source": [
    "### Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each.\n",
    "##### Answer : -\n",
    "1. Simple Linear Regression\n",
    "\n",
    "Definition: Simple linear regression models the relationship between one independent variable (predictor) and one dependent variable (response) using a straight line.\n",
    "\n",
    "Equation:h0(x)=b0+b1X1\n",
    "\n",
    "Example: Predicting a person's salary based on their years of experience:\n",
    "\n",
    "Independent variable (X): Years of experience.\n",
    "\n",
    "Dependent variable (Y): Salary.\n",
    "\n",
    "2. Multiple Linear Regression\n",
    "\n",
    "Definition: Multiple linear regression models the relationship between two or more independent variables and one dependent variable. It generalizes the simple linear regression by using more predictors.\n",
    "\n",
    "Equation:h0(x)=b0+ b1X1 + b2x2 + b3x3 +.......+bnxn\n",
    "\n",
    "Example: Predicting a person's salary based on years of experience, education level, and age:\n",
    "\n",
    "Independent variables (X): Years of experience, education level, and age.\n",
    "\n",
    "Dependent variable (Y): Salary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751cc1a-7a8e-40a9-a107-a7d3b12539f1",
   "metadata": {},
   "source": [
    "### Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset ?\n",
    "##### Answer :- \n",
    "\n",
    "Assumptions of Linear Regression:\n",
    "\n",
    "Linearity: The relationship between the independent and dependent variables should be linear.\n",
    "\n",
    "Check: Plot the independent variable(s) against the dependent variable to see if the relationship is approximately linear.\n",
    "\n",
    "Independence of Errors: The residuals (errors) should be independent of each other.\n",
    "\n",
    "Check: Use the Durbin-Watson test for autocorrelation, especially in time series data.\n",
    "\n",
    "Homoscedasticity: The residuals should have constant variance at all levels of the independent variables.\n",
    "\n",
    "Check: Plot residuals vs. fitted values; if the spread of residuals is consistent, homoscedasticity holds.\n",
    "\n",
    "Normality of Residuals: The residuals should be normally distributed.\n",
    "\n",
    "Check: Use a Q-Q plot or a histogram of residuals. Also, the Shapiro-Wilk test can help check normality.\n",
    "\n",
    "No Multicollinearity (For Multiple Linear Regression): The independent variables should not be highly correlated with each other.\n",
    "\n",
    "Check: Calculate the Variance Inflation Factor (VIF); VIF > 10 indicates high multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592c9b18-0ee3-4314-ae48-608ebc098106",
   "metadata": {},
   "source": [
    "### Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario.\n",
    "##### Answer :-\n",
    "\n",
    "Interpreting the Slope and Intercept in Linear Regression:\n",
    "\n",
    "1. Slope: The slope (b1) represents the change in the dependent variable (Y) for each unit increase in the independent variable (X). It indicates how much ùëå changes as X increases by 1 unit.\n",
    "Interpretation: If the slope is positive, Y increases with X; if negative, Y decreases with X\n",
    "\n",
    "2. Intercept: The intercept (b0) is the predicted value of the dependent variable (Y) when the independent variable (X) is zero. It shows the starting point of Y when ùëã=0.\n",
    "\n",
    "Interpretation: The intercept may not always be meaningful in some real-world contexts, especially if X=0 doesn‚Äôt make sense.\n",
    "\n",
    "Real-World Example:\n",
    "\n",
    "Scenario: Predicting monthly salary based on years of experience.\n",
    "\n",
    "Model:\n",
    "\n",
    "Salary=30,000+5,000√óYears¬†of¬†Experience\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "Slope: For every additional year of experience, the salary increases by 5,000 units (e.g., rupees, dollars).\n",
    "\n",
    "Intercept: When the years of experience is zero, the starting salary is 30,000 units. This represents the baseline salary for someone with no experience.\n",
    "\n",
    "In this case:\n",
    "\n",
    "If a person has 3 years of experience, the predicted salary would be:\n",
    "\n",
    "Salary=30,000+5,000√ó3=45,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd9d72e-2bc6-4709-82c2-4b11201e1b62",
   "metadata": {},
   "source": [
    "### Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "\n",
    "##### Answer:- \n",
    "Gradient Descent is an optimization algorithm used to minimize a function by iteratively moving towards the function‚Äôs minimum. In machine learning, it's commonly used to minimize the cost function (or loss function), which measures how well a model fits the data.\n",
    "\n",
    "How Gradient Descent Works:\n",
    "\n",
    "Initialize Parameters: Start with random or zero values for weights (w) and bias(b).\n",
    "\n",
    "Calculate Gradient: Compute the partial derivatives of the cost function with respect to each parameter (weights and bias).\n",
    "\n",
    "Update Parameters: Update the weights and bias by moving in the direction opposite to the gradient.\n",
    "\n",
    "Repeat: Iterate this process until the cost function converges (i.e., the change in the cost function is very small).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3421a2-0744-4001-8325-0a642a510770",
   "metadata": {},
   "source": [
    "### Q5. Describe the multiple linear regression model. How does it differ from simple linear regression? \n",
    "\n",
    "##### Answer:- \n",
    "\n",
    "Multiple Linear Regression Model:\n",
    "\n",
    "Multiple Linear Regression is an extension of simple linear regression that models the relationship between two or more independent variables and a single dependent variable. It predicts the dependent variable based on a linear combination of the independent variables.\n",
    "\n",
    "Difference Between Multiple Linear Regression and Simple Linear Regression:\n",
    "\n",
    "Number of Predictors:\n",
    "Simple Linear Regression: Uses one independent variable.\n",
    "Multiple Linear Regression: Uses two or more independent variables.\n",
    "\n",
    "Complexity:\n",
    "Simple Linear Regression: Easier to visualize and interpret since it deals with a single predictor.\n",
    "Multiple Linear Regression: More complex, especially when interpreting the impact of multiple variables on the dependent variable.\n",
    "\n",
    "Use Case:\n",
    "\n",
    "Simple Linear Regression: Suitable when predicting based on one factor (e.g., predicting sales based on advertising).\n",
    "\n",
    "Multiple Linear Regression: Suitable when the outcome is influenced by several factors (e.g., predicting sales based on advertising, pricing, and competition)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada74f2f-68b2-4897-8753-e952a134837e",
   "metadata": {},
   "source": [
    "### Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue ?\n",
    "##### Answer:-\n",
    "Multicollinearity occurs in multiple linear regression when two or more independent variables are highly correlated with each other. This means that one predictor variable can be linearly predicted from others with a significant degree of accuracy. As a result, it becomes difficult to determine the individual effect of each independent variable on the dependent variable, leading to unreliable coefficient estimates.\n",
    "\n",
    "How to Detect Multicollinearity:\n",
    "\n",
    "Variance Inflation Factor (VIF):\n",
    "VIF measures how much the variance of the regression coefficients is inflated due to multicollinearity. A high VIF (> 10) suggests high multicollinearity.\n",
    "\n",
    "Rule of Thumb: VIF > 10 indicates high multicollinearity, though values above 5 are sometimes considered problematic.\n",
    "\n",
    "Correlation Matrix:\n",
    "Check the pairwise correlations between the independent variables. If the correlation between two or more independent variables is high (usually |r‚à£>0.8), it suggests multicollinearity.\n",
    "\n",
    "Eigenvalues and Condition Number: A high condition number (greater than 30) indicates multicollinearity. This is found by performing eigenvalue decomposition of the correlation matrix of the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac047422-9922-4821-b235-e5a6f34ffbb2",
   "metadata": {},
   "source": [
    "### Q7. Describe the polynomial regression model. How is it different from linear regression ?\n",
    "##### Answer:-\n",
    "\n",
    "Polynomial Regression is a type of regression analysis in which the relationship between the independent variable (X) and the dependent variable (Y) is modeled as an n-th degree polynomial. Unlike linear regression, which fits a straight line to the data, polynomial regression fits a curve.\n",
    "\n",
    "Fit:\n",
    "\n",
    "Linear Regression: Fits a straight line to the data.\n",
    "Polynomial Regression: Fits a curve that can capture more complex relationships between ùëã and Y.\n",
    "\n",
    "Flexibility:\n",
    "\n",
    "Linear Regression: Limited to linear relationships; may not fit complex patterns.\n",
    "Polynomial Regression: Can model more complex, non-linear relationships by increasing the degree of the polynomial.\n",
    "\n",
    "Overfitting:\n",
    "\n",
    "Linear Regression: Less prone to overfitting unless the model is too simple.\n",
    "Polynomial Regression: Higher-degree polynomials can lead to overfitting, where the model captures noise rather than the underlying pattern.\n",
    "\n",
    "Interpretability:\n",
    "\n",
    "Linear Regression: Easier to interpret as the relationship is straightforward.\n",
    "Polynomial Regression: More complex interpretation due to the inclusion of multiple polynomial terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c1956b-c6e7-4856-ad11-f5674cb06cb7",
   "metadata": {},
   "source": [
    "### Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?\n",
    "##### Answer:-\n",
    "\n",
    "#### Advantages:\n",
    "\n",
    "Handles Non-Linearity:  Polynomial regression can model complex, non-linear relationships between the independent and dependent variables, which linear regression cannot capture.\n",
    "\n",
    "Flexibility: By increasing the degree of the polynomial, you can fit a wide range of data patterns and curves, making it adaptable to different types of data.\n",
    "\n",
    "Improved Fit for Complex Data:  For data that exhibits curvature or other complex trends, polynomial regression can provide a better fit than linear regression.\n",
    "\n",
    "#### Disadvantages:\n",
    "\n",
    "Overfitting:  Higher-degree polynomials can lead to overfitting, where the model captures noise and small fluctuations in the training data rather than the true underlying trend.\n",
    "\n",
    "Complexity:  Polynomial regression introduces more complexity in the model, which can make interpretation and visualization more challenging.\n",
    "\n",
    "Computational Cost: Fitting higher-degree polynomials can be computationally expensive and may require more complex algorithms.\n",
    "\n",
    "Extrapolation Issues:  Polynomial regression can behave erratically outside the range of the training data, leading to unrealistic predictions for unseen values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c942c2-ca97-4f87-8448-a9803bb8c152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
